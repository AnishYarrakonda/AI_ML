{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Advanced\n",
    "\n",
    "This notebook builds on pandas fundamentals and focuses on advanced indexing, grouping, time series, and performance patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "pd.set_option(\"display.max_columns\", 30)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Index Mastery (Beyond Basics)\n",
    "MultiIndex creation/manipulation, index alignment, and cross-section slicing.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# MultiIndex creation\n",
    "idx = pd.MultiIndex.from_product(\n",
    "    [[\"US\", \"CA\"], [\"A\", \"B\", \"C\"]],\n",
    "    names=[\"country\", \"segment\"]\n",
    ")\n",
    "\n",
    "s = pd.Series(np.arange(len(idx)), index=idx)\n",
    "s\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# set_index / reset_index\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"country\": [\"US\", \"US\", \"CA\", \"CA\"],\n",
    "    \"segment\": [\"A\", \"B\", \"A\", \"B\"],\n",
    "    \"value\": [10, 20, 15, 25]\n",
    "})\n",
    "\n",
    "mi = df.set_index([\"country\", \"segment\"])\n",
    "mi\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mi.reset_index()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# swaplevel / reorder_levels\n",
    "mi_swapped = mi.swaplevel(0, 1)\n",
    "mi_swapped\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mi_reordered = mi.reorder_levels([1, 0])\n",
    "mi_reordered\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# .xs() cross-section slicing\n",
    "mi.xs(\"US\", level=\"country\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Index alignment rules: operations align on labels\n",
    "left = pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])\n",
    "right = pd.Series([10, 20, 30], index=[\"b\", \"c\", \"d\"])\n",
    "\n",
    "left + right  # aligns on index labels, produces NaN where missing\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced Groupby Patterns\n",
    "Named aggregations, transform vs apply vs agg, and group-wise normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = pd.DataFrame({\n",
    "    \"team\": [\"A\", \"A\", \"B\", \"B\", \"B\"],\n",
    "    \"player\": [\"p1\", \"p2\", \"p3\", \"p4\", \"p5\"],\n",
    "    \"points\": [10, 15, 7, 12, 20],\n",
    "    \"assists\": [3, 5, 2, 4, 6]\n",
    "})\n",
    "\n",
    "df\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Named aggregations\n",
    "agg = df.groupby(\"team\").agg(\n",
    "    points_mean=(\"points\", \"mean\"),\n",
    "    points_max=(\"points\", \"max\"),\n",
    "    assists_sum=(\"assists\", \"sum\")\n",
    ")\n",
    "agg\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Multiple aggregations per column\n",
    "multi_agg = df.groupby(\"team\")[\"points\"].agg([\"mean\", \"min\", \"max\"]) \n",
    "multi_agg\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# transform (same shape as original) vs apply vs agg\n",
    "\n",
    "# Group-wise z-score (transform)\n",
    "points_z = df.groupby(\"team\")[\"points\"].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "# apply is flexible but slower (returns arbitrary shape)\n",
    "apply_example = df.groupby(\"team\").apply(lambda g: g.nlargest(1, \"points\"))\n",
    "\n",
    "points_z, apply_example\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Group-wise normalization and ranking\n",
    "\n",
    "df[\"points_rank\"] = df.groupby(\"team\")[\"points\"].rank(ascending=False)\n",
    "df[\"points_share\"] = df[\"points\"] / df.groupby(\"team\")[\"points\"].transform(\"sum\")\n",
    "\n",
    "df\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Time-based groupby (year, month)\n",
    "\n",
    "dates = pd.date_range(\"2024-01-01\", periods=8, freq=\"D\")\n",
    "values = np.arange(8) * 10\n",
    "\n",
    "ts = pd.DataFrame({\"date\": dates, \"value\": values}).set_index(\"date\")\n",
    "\n",
    "ts.groupby(ts.index.month).mean()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Window / Rolling / Expanding Ops\n",
    "rolling, expanding, ewm, grouped rolling, centered windows.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "s = pd.Series([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "s.rolling(window=3).mean()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Centered vs trailing windows\n",
    "s.rolling(window=3, center=True).mean()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Expanding (cumulative)\n",
    "s.expanding().mean()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Exponentially weighted moving average\n",
    "s.ewm(alpha=0.3).mean()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Custom rolling function\n",
    "s.rolling(window=3).apply(lambda x: x.max() - x.min())\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Grouped rolling\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"team\": [\"A\", \"A\", \"A\", \"B\", \"B\", \"B\"],\n",
    "    \"game\": [1, 2, 3, 1, 2, 3],\n",
    "    \"points\": [10, 12, 9, 7, 14, 11]\n",
    "})\n",
    "\n",
    "df[\"rolling_points\"] = (\n",
    "    df.groupby(\"team\")[\"points\"]\n",
    "      .rolling(window=2, min_periods=1)\n",
    "      .mean()\n",
    "      .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "df\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time Series Internals\n",
    "DatetimeIndex, PeriodIndex, TimedeltaIndex, resampling, time zones.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# DatetimeIndex\n",
    "rng = pd.date_range(\"2024-01-01\", periods=5, freq=\"D\")\n",
    "\n",
    "ts = pd.Series([5, 3, 6, 2, 7], index=rng)\n",
    "\n",
    "ts\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Resampling vs grouping\n",
    "\n",
    "ts.resample(\"2D\").mean()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# PeriodIndex\n",
    "pi = pd.period_range(\"2024Q1\", periods=4, freq=\"Q\")\n",
    "pi\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TimedeltaIndex\n",
    "\n",
    "durations = pd.to_timedelta([\"1D\", \"2D\", \"3D\"])\n",
    "durations\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Time-zone aware data\n",
    "\n",
    "tz_rng = pd.date_range(\"2024-01-01\", periods=3, freq=\"H\", tz=\"UTC\")\n",
    "tz_series = pd.Series([1, 2, 3], index=tz_rng)\n",
    "\n",
    "# Convert to US/Eastern\n",
    "\n",
    "tz_series.tz_convert(\"US/Eastern\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Offsets and business calendars\n",
    "biz = pd.date_range(\"2024-01-01\", periods=5, freq=\"B\")\n",
    "biz\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Irregular time series handling\n",
    "\n",
    "irregular = pd.Series([1, 4, 2], index=pd.to_datetime([\"2024-01-01\", \"2024-01-03\", \"2024-01-10\"]))\n",
    "\n",
    "# Reindex to daily, fill missing\n",
    "irregular.reindex(pd.date_range(\"2024-01-01\", \"2024-01-10\"), method=\"ffill\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Joins & Reshaping\n",
    "merge_asof, joins on index vs columns, pivot vs pivot_table, melt/stack.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# merge_asof: nearest key match (sorted keys required)\n",
    "\n",
    "left = pd.DataFrame({\n",
    "    \"time\": pd.to_datetime([\"2024-01-01 09:00\", \"2024-01-01 09:05\", \"2024-01-01 09:10\"]),\n",
    "    \"price\": [100, 101, 102]\n",
    "}).sort_values(\"time\")\n",
    "\n",
    "right = pd.DataFrame({\n",
    "    \"time\": pd.to_datetime([\"2024-01-01 09:02\", \"2024-01-01 09:07\"]),\n",
    "    \"event\": [\"A\", \"B\"]\n",
    "}).sort_values(\"time\")\n",
    "\n",
    "pd.merge_asof(left, right, on=\"time\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Join on index vs columns\n",
    "\n",
    "left = pd.DataFrame({\"id\": [1, 2, 3], \"name\": [\"Ana\", \"Ben\", \"Cara\"]}).set_index(\"id\")\n",
    "right = pd.DataFrame({\"id\": [2, 3, 4], \"team\": [\"X\", \"Y\", \"Z\"]}).set_index(\"id\")\n",
    "\n",
    "left.join(right, how=\"left\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Many-to-many join explosion risk\n",
    "\n",
    "left = pd.DataFrame({\"key\": [1, 1], \"val_l\": [\"a\", \"b\"]})\n",
    "right = pd.DataFrame({\"key\": [1, 1, 1], \"val_r\": [\"x\", \"y\", \"z\"]})\n",
    "\n",
    "pd.merge(left, right, on=\"key\")  # 2 x 3 -> 6 rows\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# pivot vs pivot_table\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"city\": [\"A\", \"A\", \"B\", \"B\"],\n",
    "    \"year\": [2023, 2024, 2023, 2024],\n",
    "    \"value\": [10, 12, 8, 9]\n",
    "})\n",
    "\n",
    "pivoted = df.pivot(index=\"city\", columns=\"year\", values=\"value\")\n",
    "pivoted\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# pivot_table supports aggregation\n",
    "\n",
    "df_dup = pd.DataFrame({\n",
    "    \"city\": [\"A\", \"A\", \"A\"],\n",
    "    \"year\": [2024, 2024, 2024],\n",
    "    \"value\": [10, 12, 14]\n",
    "})\n",
    "\n",
    "pd.pivot_table(df_dup, index=\"city\", columns=\"year\", values=\"value\", aggfunc=\"mean\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# melt / stack / unstack\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"id\": [1, 2],\n",
    "    \"x\": [10, 20],\n",
    "    \"y\": [30, 40]\n",
    "})\n",
    "\n",
    "melted = df.melt(id_vars=[\"id\"], value_vars=[\"x\", \"y\"], var_name=\"var\", value_name=\"val\")\n",
    "\n",
    "melted\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "stacked = df.set_index(\"id\").stack()\n",
    "stacked\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "unstacked = stacked.unstack()\n",
    "unstacked\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Memory & Performance\n",
    "Categorical dtype, nullable dtypes, chunked processing, vectorization patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Copy vs view semantics (pandas often copies)\n",
    "\n",
    "df = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n",
    "\n",
    "slice_df = df[[\"a\", \"b\"]]    # likely a new object\n",
    "slice_df is df\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Categorical dtype to save memory\n",
    "\n",
    "cities = pd.Series([\"Austin\", \"Austin\", \"Boston\", \"Austin\", \"Boston\"], dtype=\"category\")\n",
    "cities.dtype\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Nullable dtypes\n",
    "\n",
    "s = pd.Series([1, None, 3], dtype=\"Int64\")\n",
    "s\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Chunked processing\n",
    "\n",
    "csv_path = \"big_sample.csv\"\n",
    "\n",
    "pd.DataFrame({\"x\": np.arange(1000), \"y\": np.random.randn(1000)}).to_csv(csv_path, index=False)\n",
    "\n",
    "chunk_sums = []\n",
    "for chunk in pd.read_csv(csv_path, chunksize=200):\n",
    "    chunk_sums.append(chunk[\"y\"].sum())\n",
    "\n",
    "sum(chunk_sums)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Vectorization pattern\n",
    "\n",
    "df = pd.DataFrame({\"x\": np.arange(5), \"y\": np.arange(5, 10)})\n",
    "\n",
    "# Avoid loops, use vectorized ops\n",
    "\n",
    "df[\"z\"] = df[\"x\"] * 2 + df[\"y\"]\n",
    "\n",
    "df\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Indexing & Assignment\n",
    "Boolean indexing pitfalls, chained assignment, .loc vs .iloc, masked assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = pd.DataFrame({\"a\": [1, 2, 3, 4], \"b\": [10, 20, 30, 40]})\n",
    "\n",
    "# Boolean indexing\n",
    "mask = df[\"a\"] % 2 == 0\n",
    "\n",
    "filtered = df[mask]\n",
    "filtered\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Chained assignment (avoid)\n",
    "# df[mask][\"b\"] = 999  # SettingWithCopyWarning\n",
    "\n",
    "# Use .loc for safe mutation\n",
    "\n",
    "df.loc[mask, \"b\"] = 999\n",
    "\n",
    "df\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Index alignment during assignment\n",
    "\n",
    "s = pd.Series([100, 200], index=[0, 3])\n",
    "\n",
    "df[\"b\"] = s  # aligns on index, introduces NaN for missing\n",
    "\n",
    "df\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Custom Functions at Scale\n",
    "Use NumPy inside pandas pipelines and avoid Python loops.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = pd.DataFrame({\"a\": np.arange(5), \"b\": np.arange(5, 10)})\n",
    "\n",
    "def fast_fn(x):\n",
    "    # vectorized inside pandas\n",
    "    return np.sqrt(x**2 + 1)\n",
    "\n",
    "out = df[\"a\"].pipe(fast_fn)\n",
    "out\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Broadcasting tricks with DataFrames\n",
    "\n",
    "A = pd.DataFrame(np.arange(6).reshape(3, 2), columns=[\"x\", \"y\"])\n",
    "\n",
    "# Subtract column means (broadcast across rows)\n",
    "A - A.mean(axis=0)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Validation & Consistency\n",
    "Schema checks, duplicate detection, integrity checks after joins.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = pd.DataFrame({\n",
    "    \"id\": [1, 2, 2, 3],\n",
    "    \"value\": [10, 20, 20, 30]\n",
    "})\n",
    "\n",
    "# Detect duplicates on multiple keys\n",
    "\n",
    "df.duplicated(subset=[\"id\", \"value\"], keep=False)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Integrity check after join\n",
    "\n",
    "left = pd.DataFrame({\"id\": [1, 2, 3], \"x\": [10, 20, 30]})\n",
    "right = pd.DataFrame({\"id\": [2, 3], \"y\": [200, 300]})\n",
    "\n",
    "joined = left.merge(right, on=\"id\", how=\"left\", validate=\"one_to_one\")\n",
    "joined\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Missing-data propagation\n",
    "\n",
    "s = pd.Series([1.0, np.nan, 3.0])\n",
    "\n",
    "s + 1  # NaN propagates\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interoperability & Pipelines\n",
    "Pandas <-> NumPy <-> matplotlib, scikit-learn, and method chaining.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Pandas -> NumPy\n",
    "\n",
    "df = pd.DataFrame({\"x\": [1, 2, 3], \"y\": [4, 5, 6]})\n",
    "arr = df.to_numpy()\n",
    "arr\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Pandas -> matplotlib\n",
    "\n",
    "ax = df.plot(kind=\"line\", x=\"x\", y=\"y\", title=\"Simple Line\")\n",
    "plt.show()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Pandas -> scikit-learn (if installed)\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# scaled = scaler.fit_transform(df[[\"x\", \"y\"]])\n",
    "# scaled\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Method chaining with .pipe\n",
    "\n",
    "def add_ratio(df):\n",
    "    return df.assign(ratio=df[\"y\"] / df[\"x\"])\n",
    "\n",
    "chained = (\n",
    "    df\n",
    "    .query(\"x > 1\")\n",
    "    .pipe(add_ratio)\n",
    "    .sort_values(\"ratio\", ascending=False)\n",
    ")\n",
    "\n",
    "chained\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}