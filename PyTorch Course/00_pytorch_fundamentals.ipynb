{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca421f2d",
   "metadata": {},
   "source": [
    "# PyTorch Fundamentals (Rebuilt)\n",
    "\n",
    "Clean walkthrough with comments, headers, and subheaders for your listed topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166771a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.10.0\n",
      "numpy: 2.3.2\n"
     ]
    }
   ],
   "source": [
    "# Import core libraries for deep learning and numerical computing\n",
    "import torch  # PyTorch: framework for neural networks and tensor computations\n",
    "import numpy as np  # NumPy: fundamental package for numerical computing\n",
    "\n",
    "print('torch:', torch.__version__)\n",
    "print('numpy:', np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0584ab15",
   "metadata": {},
   "source": [
    "## 13. Introduction to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc58811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7) 0 torch.Size([])\n",
      "tensor([1, 2, 3]) 1 torch.Size([3])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]]) 2 torch.Size([2, 2])\n",
      "3 torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Tensors are the fundamental data structure in PyTorch\n",
    "# They are n-dimensional arrays that can be processed on GPUs for fast computation\n",
    "# ndim = number of dimensions, shape = size of each dimension\n",
    "\n",
    "scalar = torch.tensor(7)  # 0D tensor: just a single number\n",
    "vector = torch.tensor([1, 2, 3])  # 1D tensor: ordered list of numbers\n",
    "matrix = torch.tensor([[1, 2], [3, 4]])  # 2D tensor: grid of numbers (rows × cols)\n",
    "tensor3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])  # 3D tensor: cube of numbers\n",
    "\n",
    "print(scalar, scalar.ndim, scalar.shape)\n",
    "print(vector, vector.ndim, vector.shape)\n",
    "print(matrix, matrix.ndim, matrix.shape)\n",
    "print(tensor3d.ndim, tensor3d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d550e",
   "metadata": {},
   "source": [
    "## 14. Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d897aca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([0, 2, 4, 6, 8])\n",
      "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n",
      "tensor([[0.1654, 0.1851, 0.7770],\n",
      "        [0.9154, 0.7491, 0.7944]])\n",
      "tensor([[9, 3, 8],\n",
      "        [2, 5, 7]])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch provides convenient functions to create tensors with specific patterns\n",
    "# These are useful for initializing tensors in neural networks\n",
    "\n",
    "zeros = torch.zeros((2, 3))  # Create a 2×3 tensor filled with zeros\n",
    "ones = torch.ones((2, 3))  # Create a 2×3 tensor filled with ones\n",
    "ar = torch.arange(0, 10, 2)  # Create tensor with evenly spaced values: start, end, step\n",
    "lin = torch.linspace(0, 1, 5)  # Create tensor with 5 evenly spaced values from 0 to 1\n",
    "rand = torch.rand((2, 3))  # Create 2×3 tensor with random values from uniform distribution [0, 1)\n",
    "randi = torch.randint(0, 10, (2, 3))  # Create 2×3 tensor with random integers from 0 to 9\n",
    "\n",
    "print(zeros)\n",
    "print(ones)\n",
    "print(ar)\n",
    "print(lin)\n",
    "print(rand)\n",
    "print(randi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe90311",
   "metadata": {},
   "source": [
    "## 17. Tensor datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81855ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 torch.float32 torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Tensor dtype specifies the data type of values (memory and precision trade-off)\n",
    "# Common types: int32, int64, float32 (default), float64 (double)\n",
    "# Higher precision (float64) uses more memory; float32 is typical for deep learning\n",
    "\n",
    "a = torch.tensor([1, 2, 3])  # Default: int64 (inferred from integer input)\n",
    "b = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)  # Explicitly set to float32\n",
    "c = b.to(torch.float64)  # Convert tensor to float64 using .to() method\n",
    "\n",
    "print(a.dtype, b.dtype, c.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f872b03d",
   "metadata": {},
   "source": [
    "## 18. Tensor attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5e538af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([3, 4])\n",
      "ndim: 2\n",
      "dtype: torch.float32\n",
      "device: cpu\n",
      "numel: 12\n"
     ]
    }
   ],
   "source": [
    "# Every tensor has key attributes that define its structure and properties\n",
    "# Understanding these helps debug shape mismatches and device issues\n",
    "\n",
    "t = torch.rand((3, 4), dtype=torch.float32)\n",
    "print('shape:', t.shape)  # shape: size of each dimension as a tuple (3, 4)\n",
    "print('ndim:', t.ndim)  # ndim: number of dimensions (2 for a matrix)\n",
    "print('dtype:', t.dtype)  # dtype: data type of elements (torch.float32)\n",
    "print('device:', t.device)  # device: where tensor lives (CPU, GPU, etc.)\n",
    "print('numel:', t.numel())  # numel: total number of elements (3×4 = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714c4f12",
   "metadata": {},
   "source": [
    "## 19. Manipulating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "448fdd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add: tensor([11, 22, 33])\n",
      "sub: tensor([ 9, 18, 27])\n",
      "mul elementwise: tensor([10, 40, 90])\n",
      "div: tensor([10., 10., 10.])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise operations: operate on corresponding elements at the same position\n",
    "# These are the fundamental building blocks of neural network computations\n",
    "\n",
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([10, 20, 30])\n",
    "\n",
    "print('add:', x + y)  # [11, 22, 33] - add corresponding elements\n",
    "print('sub:', y - x)  # [9, 18, 27] - subtract corresponding elements\n",
    "print('mul elementwise:', x * y)  # [10, 40, 90] - multiply corresponding elements (Hadamard product)\n",
    "print('div:', y / x)  # [10, 10, 10] - divide corresponding elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa244c1b",
   "metadata": {},
   "source": [
    "## 20. Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "407f6a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1 shape: torch.Size([2, 3])\n",
      "m2 shape: torch.Size([3, 2])\n",
      "matmul: tensor([[ 58.,  64.],\n",
      "        [139., 154.]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication (matmul) is different from element-wise multiplication\n",
    "# It's essential for neural networks: output = input @ weight + bias\n",
    "# Rule: (m×n) @ (n×p) = (m×p) - inner dimensions must match!\n",
    "\n",
    "m1 = torch.tensor([[1., 2., 3.], [4., 5., 6.]])  # Shape: (2, 3) - 2 rows, 3 columns\n",
    "m2 = torch.tensor([[7., 8.], [9., 10.], [11., 12.]])  # Shape: (3, 2) - 3 rows, 2 columns\n",
    "print('m1 shape:', m1.shape)  # (2, 3)\n",
    "print('m2 shape:', m2.shape)  # (3, 2)\n",
    "print('matmul:', m1 @ m2)  # Result shape: (2, 2) - inner 3's cancel out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f25a0",
   "metadata": {},
   "source": [
    "## 23. Finding min, max, mean, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fa7a789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: tensor(1.)\n",
      "max: tensor(9.)\n",
      "mean: tensor(4.)\n",
      "sum: tensor(20.)\n",
      "argmin: tensor(2)\n",
      "argmax: tensor(3)\n"
     ]
    }
   ],
   "source": [
    "# Aggregation operations: reduce tensors to single values or indices\n",
    "# These are used for loss computation, finding predictions, and model evaluation\n",
    "\n",
    "v = torch.tensor([2.0, 5.0, 1.0, 9.0, 3.0])\n",
    "print('min:', v.min())  # Minimum value in tensor: 1.0\n",
    "print('max:', v.max())  # Maximum value in tensor: 9.0\n",
    "print('mean:', v.mean())  # Average of all elements: (2+5+1+9+3)/5 = 4.0\n",
    "print('sum:', v.sum())  # Sum of all elements: 2+5+1+9+3 = 20.0\n",
    "print('argmin:', v.argmin())  # Index of minimum value: 2 (v[2] = 1.0)\n",
    "print('argmax:', v.argmax())  # Index of maximum value: 3 (v[3] = 9.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a714eb6f",
   "metadata": {},
   "source": [
    "## 25. Reshaping, viewing and stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbf00844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base: tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n",
      "reshape 3x4: tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "view 2x6: tensor([[ 1,  2,  3,  4,  5,  6],\n",
      "        [ 7,  8,  9, 10, 11, 12]])\n",
      "stack dim0: tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "stack dim1: tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Reshaping changes the shape without changing the underlying data (reinterpretation)\n",
    "# Stacking combines multiple tensors along a new or existing dimension\n",
    "# These operations are critical for preparing data for neural networks\n",
    "\n",
    "base = torch.arange(1, 13)  # Create tensor [1, 2, 3, ..., 12] (flat, 1D)\n",
    "reshaped = base.reshape(3, 4)  # Reinterpret as 3 rows × 4 columns (same 12 elements)\n",
    "viewed = base.view(2, 6)  # Alternative: view same 12 elements as 2 rows × 6 columns\n",
    "\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "print('base:', base)\n",
    "print('reshape 3x4:', reshaped)\n",
    "print('view 2x6:', viewed)\n",
    "print('stack dim0:', torch.stack([a, b], dim=0))  # Stack along new dimension 0 → (2, 3)\n",
    "print('stack dim1:', torch.stack([a, b], dim=1))  # Stack along new dimension 1 → (3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72487e0e",
   "metadata": {},
   "source": [
    "## 26. Squeezing, unsqueezing and permuting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "150c7258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: torch.Size([1, 3, 1, 5])\n",
      "squeezed: torch.Size([3, 5])\n",
      "unsqueezed: torch.Size([1, 3, 5])\n",
      "NCHW: torch.Size([2, 3, 32, 32])\n",
      "NHWC: torch.Size([2, 32, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "# squeeze: removes dimensions of size 1 (useful for cleaning up tensor shapes)\n",
    "# unsqueeze: adds a dimension of size 1 at a specific position\n",
    "# permute: rearranges dimensions (useful for converting between data formats)\n",
    "\n",
    "q = torch.randn(1, 3, 1, 5)  # Shape (1, 3, 1, 5) has redundant dimensions of size 1\n",
    "print('original:', q.shape)  # (1, 3, 1, 5)\n",
    "print('squeezed:', q.squeeze().shape)  # (3, 5) - removed all dimensions of size 1\n",
    "\n",
    "u = q.squeeze().unsqueeze(0)  # Add dimension back at position 0\n",
    "print('unsqueezed:', u.shape)  # (1, 3, 5) - new dimension at front\n",
    "\n",
    "# Common in computer vision: NCHW (PyTorch) vs NHWC (NumPy/TensorFlow) formats\n",
    "# N=batch size, C=channels, H=height, W=width\n",
    "img = torch.randn(2, 3, 32, 32)  # 2 images, 3 color channels, 32×32 pixels each (NCHW)\n",
    "print('NCHW:', img.shape)  # (2, 3, 32, 32)\n",
    "print('NHWC:', img.permute(0, 2, 3, 1).shape)  # (2, 32, 32, 3) - rearrange to NHWC format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9715b5",
   "metadata": {},
   "source": [
    "## 27. Selecting data (indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17709089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first row: tensor([10, 20, 30])\n",
      "last col: tensor([30, 60, 90])\n",
      "center: tensor(50)\n",
      "slice: tensor([[20, 30],\n",
      "        [50, 60]])\n",
      "mask > 45: tensor([50, 60, 70, 80, 90])\n"
     ]
    }
   ],
   "source": [
    "# Indexing: access specific elements, rows, columns, or subsets using different methods\n",
    "# Essential for slicing data batches and extracting specific features from tensors\n",
    "\n",
    "idx = torch.tensor([[10, 20, 30], [40, 50, 60], [70, 80, 90]])  # 3×3 matrix\n",
    "\n",
    "print('first row:', idx[0])  # [10, 20, 30] - get entire first row\n",
    "print('last col:', idx[:, -1])  # [30, 60, 90] - get last column (all rows, last column)\n",
    "print('center:', idx[1, 1])  # 50 - get element at row 1, column 1\n",
    "print('slice:', idx[0:2, 1:3])  # Get rows 0-1, columns 1-2 (2×2 submatrix)\n",
    "print('mask > 45:', idx[idx > 45])  # [50, 60, 70, 80, 90] - Boolean masking: get all elements > 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d080a51",
   "metadata": {},
   "source": [
    "## 28. PyTorch and NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "274dd94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch from numpy: tensor([99.,  2.,  3.])\n",
      "numpy from torch: [10. -5. 30.]\n"
     ]
    }
   ],
   "source": [
    "# PyTorch and NumPy can share memory (torch.from_numpy) for efficient conversions\n",
    "# This means changes to one affect the other - useful but also needs care!\n",
    "# torch.tensor creates a copy, torch.from_numpy shares memory\n",
    "\n",
    "arr = np.array([1.0, 2.0, 3.0], dtype=np.float32)\n",
    "t_from_np = torch.from_numpy(arr)  # Convert NumPy → PyTorch (SHARES memory)\n",
    "\n",
    "t = torch.tensor([10.0, 20.0, 30.0])\n",
    "arr_from_t = t.numpy()  # Convert PyTorch → NumPy (SHARES memory)\n",
    "\n",
    "# Modify original array and tensor - changes propagate to the shared tensor!\n",
    "arr[0] = 99.0  # Changes NumPy array\n",
    "t[1] = -5.0  # Changes PyTorch tensor\n",
    "\n",
    "print('torch from numpy:', t_from_np)  # Notice arr[0] changed, so this changed too\n",
    "print('numpy from torch:', arr_from_t)  # Notice t[1] changed, so this changed too"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c02d462",
   "metadata": {},
   "source": [
    "## 29. Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c26930a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1: tensor([0.8823, 0.9150, 0.3829])\n",
      "r2: tensor([0.8823, 0.9150, 0.3829])\n",
      "same: True\n"
     ]
    }
   ],
   "source": [
    "# Random seeds: setting the same seed produces the same random numbers\n",
    "# Essential for reproducibility: same code + same seed = same results every time\n",
    "# This is crucial for debugging neural networks and comparing experiments fairly\n",
    "\n",
    "torch.manual_seed(42)  # Set global random seed to 42\n",
    "r1 = torch.rand(3)  # Generate random tensor with seed 42\n",
    "\n",
    "torch.manual_seed(42)  # Reset seed back to 42\n",
    "r2 = torch.rand(3)  # Generate same random tensor again\n",
    "\n",
    "print('r1:', r1)\n",
    "print('r2:', r2)\n",
    "print('same:', torch.equal(r1, r2))  # True - same seed produces identical random values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644c0efd",
   "metadata": {},
   "source": [
    "## 30. Accessing a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e27cd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "MPS available: True\n"
     ]
    }
   ],
   "source": [
    "# GPU acceleration: PyTorch can run on GPU (NVIDIA CUDA or Apple MPS) for ~50-100× speedup\n",
    "# CPU: good for small models, learning, debugging\n",
    "# GPU: essential for training large models efficiently\n",
    "# MPS (Metal Performance Shaders): Apple GPU acceleration on Mac\n",
    "\n",
    "print('CUDA available:', torch.cuda.is_available())  # Check NVIDIA GPU support\n",
    "print('MPS available:', torch.backends.mps.is_available() if hasattr(torch.backends, 'mps') else False)  # Check Apple GPU\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU:', torch.cuda.get_device_name(0))  # Print name of first GPU device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe9be12",
   "metadata": {},
   "source": [
    "## 31. Setting up device agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "943dee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "x device: mps:0\n",
      "model device: mps:0\n",
      "out shape: torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "# Device-agnostic code: write code that works on CPU, GPU, or MPS automatically\n",
    "# This is the right way to write production PyTorch code - no need to change code for different hardware\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Return the best available device for computation.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')  # Use NVIDIA GPU if available\n",
    "    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        return torch.device('mps')  # Use Apple GPU if available\n",
    "    return torch.device('cpu')  # Fallback to CPU\n",
    "\n",
    "device = get_device()\n",
    "print('Using device:', device)\n",
    "\n",
    "# .to(device) moves tensor or model to the specified device\n",
    "x = torch.randn(4, 3).to(device)  # Create tensor on the best device\n",
    "model = torch.nn.Linear(3, 2).to(device)  # Move neural network model to device\n",
    "out = model(x)  # Forward pass - computes output\n",
    "\n",
    "print('x device:', x.device)  # Show which device tensor lives on\n",
    "print('model device:', model.weight.device)  # Show which device model weights are on\n",
    "print('out shape:', out.shape)  # Output shape: (batch_size=4, output_features=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81d114",
   "metadata": {},
   "source": [
    "## Practice\n",
    "- Change shapes and predict outputs before running\n",
    "- Trigger one matrix shape mismatch to read the error\n",
    "- Verify NumPy/PyTorch shared memory behavior\n",
    "- Re-run reproducibility cell and confirm matching random values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
