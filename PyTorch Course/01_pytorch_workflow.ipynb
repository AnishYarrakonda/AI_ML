{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1fb889",
   "metadata": {},
   "source": [
    "# PyTorch Workflow: Linear Regression End-to-End\n",
    "\n",
    "This notebook covers the full linear regression workflow in PyTorch with practical intuition and coding exercises.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8827bf",
   "metadata": {},
   "source": [
    "## Topics Covered\n",
    "\n",
    "1. Creating a dataset with linear regression\n",
    "2. Creating training and test sets\n",
    "3. Creating our first PyTorch model\n",
    "4. Important model-building classes\n",
    "5. Checking model internals\n",
    "6. Making predictions with our model\n",
    "7. Training a model with PyTorch (intuition)\n",
    "8. Setting up a loss function and optimizer\n",
    "9. Training loop intuition\n",
    "10. Running training loop epoch by epoch\n",
    "11. Writing testing loop code\n",
    "12. Saving and loading a model\n",
    "13. Putting everything together\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6730ed",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "By the end, you should be able to:\n",
    "- Build synthetic regression data with known true parameters.\n",
    "- Split data into train/test sets correctly.\n",
    "- Define an `nn.Module` model for regression.\n",
    "- Train and evaluate with proper `train()` / `eval()` behavior.\n",
    "- Save and reload model weights safely.\n",
    "- Package the whole process into reusable functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff2595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Torch version:', torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38548dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55b35d4",
   "metadata": {},
   "source": [
    "## Creating a Dataset with Linear Regression\n",
    "\n",
    "We build a synthetic dataset from the formula:\n",
    "\n",
    "\\[\n",
    "y = w x + b\n",
    "\\]\n",
    "\n",
    "Since we choose `w` and `b`, we can verify whether training recovers those values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e01de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True parameters\n",
    "weight_true = 0.7\n",
    "bias_true = 0.3\n",
    "\n",
    "# Create input values\n",
    "X = torch.arange(0, 1, 0.02).unsqueeze(dim=1)\n",
    "\n",
    "# Create labels using the true linear relationship\n",
    "y = weight_true * X + bias_true\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bf5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize full dataset\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.scatter(X.numpy(), y.numpy(), s=18, c='royalblue')\n",
    "plt.title('Synthetic Linear Regression Data')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022ff66d",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "- Change `weight_true` and `bias_true`.\n",
    "- Regenerate `y`.\n",
    "- Re-plot the data and describe how slope/intercept changed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9290f9c",
   "metadata": {},
   "source": [
    "## Creating Training and Test Sets\n",
    "\n",
    "A model should be trained on one subset and evaluated on unseen examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5152af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "print('Train samples:', len(X_train))\n",
    "print('Test samples :', len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train vs test\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.scatter(X_train.numpy(), y_train.numpy(), s=18, c='royalblue', label='Train')\n",
    "plt.scatter(X_test.numpy(), y_test.numpy(), s=18, c='tomato', label='Test')\n",
    "plt.legend()\n",
    "plt.title('Train/Test Split')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c2c9c4",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "- Try split ratios `70/30` and `90/10`.\n",
    "- Compare how many test points each gives.\n",
    "- Which split gives a stronger estimate of generalization for this small dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b56f2b",
   "metadata": {},
   "source": [
    "## Creating Our First PyTorch Model\n",
    "\n",
    "We start with the most explicit version: two learnable parameters (`weight`, `bias`) as `nn.Parameter` objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf52bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModelV1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(1, dtype=torch.float), requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.randn(1, dtype=torch.float), requires_grad=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weight * x + self.bias\n",
    "\n",
    "\n",
    "model_0 = LinearRegressionModelV1()\n",
    "print(model_0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55870401",
   "metadata": {},
   "source": [
    "## Important Model-Building Classes\n",
    "\n",
    "- `nn.Module`: Base class for all neural network modules.\n",
    "- `nn.Parameter`: Tensor that should be optimized.\n",
    "- `nn.Linear`: Built-in affine layer (`y = xA^T + b`).\n",
    "- `torch.optim`: Optimizers like SGD/Adam.\n",
    "- Loss functions: quantify prediction error (`nn.L1Loss`, `nn.MSELoss`, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c726c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent model using nn.Linear (more common)\n",
    "class LinearRegressionModelV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(in_features=1, out_features=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear_layer(x)\n",
    "\n",
    "\n",
    "model_1 = LinearRegressionModelV2()\n",
    "print(model_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0426d1",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "- Print both `model_0` and `model_1` parameters.\n",
    "- Explain how `model_1` hides `weight`/`bias` inside `nn.Linear`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb25636",
   "metadata": {},
   "source": [
    "## Checking Out the Internals of Our Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd445b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model_0 parameters:')\n",
    "for name, param in model_0.named_parameters():\n",
    "    print(f'{name:10s} | shape={tuple(param.shape)} | value={param.data}')\n",
    "\n",
    "print('\n",
    "model_0 state_dict:')\n",
    "print(model_0.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f39f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model_1 parameters:')\n",
    "for name, param in model_1.named_parameters():\n",
    "    print(f'{name:20s} | shape={tuple(param.shape)} | value={param.data}')\n",
    "\n",
    "print('\n",
    "model_1 state_dict:')\n",
    "print(model_1.state_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad66833",
   "metadata": {},
   "source": [
    "## Making Predictions with Our Model\n",
    "\n",
    "Before training, predictions are usually poor because parameters are random.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e5f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    y_preds_before = model_0(X_test)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.scatter(X_train.numpy(), y_train.numpy(), s=18, c='royalblue', label='Train')\n",
    "plt.scatter(X_test.numpy(), y_test.numpy(), s=18, c='tomato', label='Test')\n",
    "plt.scatter(X_test.numpy(), y_preds_before.numpy(), s=18, c='seagreen', label='Predictions (before training)')\n",
    "plt.legend()\n",
    "plt.title('Predictions Before Training')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc0b18f",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "- Compare `y_preds_before[:5]` with `y_test[:5]`.\n",
    "- Estimate whether the model is over- or under-predicting on average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4244ecf2",
   "metadata": {},
   "source": [
    "## Training a Model with PyTorch (Intuition)\n",
    "\n",
    "Core cycle:\n",
    "1. Forward pass (predictions)\n",
    "2. Compute loss\n",
    "3. Zero gradients\n",
    "4. Backward pass (`loss.backward()`)\n",
    "5. Optimizer step (`optimizer.step()`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d065e789",
   "metadata": {},
   "source": [
    "## Setting Up a Loss Function and Optimizer\n",
    "\n",
    "For linear regression, `L1Loss` (MAE) is common in intro examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d61abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05249608",
   "metadata": {},
   "source": [
    "## Training Loop Intuition\n",
    "\n",
    "This short loop prints gradients to show how parameters get updated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model_0.train()\n",
    "\n",
    "for step in range(3):\n",
    "    y_pred = model_0(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    print(f'Step {step} | loss={loss.item():.5f} | grad_weight={model_0.weight.grad.item():.5f} | grad_bias={model_0.bias.grad.item():.5f}')\n",
    "\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d40cc35",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "- Increase `lr` to `0.1` and run the 3-step loop again from a fresh model.\n",
    "- What changes in gradient step behavior do you observe?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f361fd",
   "metadata": {},
   "source": [
    "## Running Our Training Loop Epoch by Epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c69c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialize model for clean training\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "model_0 = LinearRegressionModelV1()\n",
    "\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 300\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epoch_count = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_0.train()\n",
    "\n",
    "    # Training step\n",
    "    y_pred = model_0(X_train)\n",
    "    train_loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Testing step\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model_0(X_test)\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        epoch_count.append(epoch)\n",
    "        train_loss_values.append(train_loss.item())\n",
    "        test_loss_values.append(test_loss.item())\n",
    "        print(f'Epoch: {epoch:3d} | Train loss: {train_loss.item():.5f} | Test loss: {test_loss.item():.5f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca6373",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(epoch_count, train_loss_values, label='Train loss')\n",
    "plt.plot(epoch_count, test_loss_values, label='Test loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('L1 Loss')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f6d99",
   "metadata": {},
   "source": [
    "## Writing Testing Loop Code\n",
    "\n",
    "A correct testing loop should:\n",
    "- switch to `model.eval()`\n",
    "- disable gradient tracking (`torch.inference_mode()`)\n",
    "- compute metrics on unseen test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa771bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: nn.Module, X_data: torch.Tensor, y_data: torch.Tensor, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        pred = model(X_data)\n",
    "        loss = loss_fn(pred, y_data)\n",
    "    return {'loss': loss.item(), 'predictions': pred}\n",
    "\n",
    "\n",
    "test_results = evaluate_model(model_0, X_test, y_test, loss_fn)\n",
    "print('Test loss:', round(test_results['loss'], 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e25211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    y_preds_after = model_0(X_test)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.scatter(X_train.numpy(), y_train.numpy(), s=18, c='royalblue', label='Train')\n",
    "plt.scatter(X_test.numpy(), y_test.numpy(), s=18, c='tomato', label='Test')\n",
    "plt.scatter(X_test.numpy(), y_preds_after.numpy(), s=18, c='seagreen', label='Predictions (after training)')\n",
    "plt.legend()\n",
    "plt.title('Predictions After Training')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065b6a70",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "- Add `MSELoss` to the evaluation function.\n",
    "- Report both MAE and MSE for the same model.\n",
    "- Which metric is larger numerically and why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89814dbe",
   "metadata": {},
   "source": [
    "## Saving and Loading a Model\n",
    "\n",
    "Standard practice is saving the `state_dict()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c35ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path('PyTorch Course/models')\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = 'linear_regression_model_v1.pth'\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "torch.save(model_0.state_dict(), MODEL_SAVE_PATH)\n",
    "print('Saved model to:', MODEL_SAVE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights into a new model instance\n",
    "loaded_model = LinearRegressionModelV1()\n",
    "loaded_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "loaded_model.eval()\n",
    "\n",
    "# Verify predictions match\n",
    "with torch.inference_mode():\n",
    "    loaded_preds = loaded_model(X_test)\n",
    "\n",
    "same = torch.allclose(y_preds_after, loaded_preds)\n",
    "print('Loaded model predictions identical to trained model:', same)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1614d91",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "- Save `model_1` as a separate file.\n",
    "- Load it into a fresh `LinearRegressionModelV2` instance.\n",
    "- Verify test predictions are identical pre/post load.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6776c0b",
   "metadata": {},
   "source": [
    "## Putting Everything Together\n",
    "\n",
    "This section wraps the workflow into reusable functions for repeatable experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69618fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear_data(weight=0.7, bias=0.3, start=0, end=1, step=0.02):\n",
    "    X = torch.arange(start, end, step).unsqueeze(1)\n",
    "    y = weight * X + bias\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def train_test_split_tensors(X, y, split_ratio=0.8):\n",
    "    split = int(split_ratio * len(X))\n",
    "    return X[:split], y[:split], X[split:], y[split:]\n",
    "\n",
    "\n",
    "def train_linear_model(model, X_train, y_train, X_test, y_test, epochs=300, lr=0.01):\n",
    "    loss_fn = nn.L1Loss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    history = {'epoch': [], 'train_loss': [], 'test_loss': []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        y_pred = model(X_train)\n",
    "        train_loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            test_pred = model(X_test)\n",
    "            test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            history['epoch'].append(epoch)\n",
    "            history['train_loss'].append(train_loss.item())\n",
    "            history['test_loss'].append(test_loss.item())\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d9a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End-to-end run\n",
    "X_all, y_all = create_linear_data(weight=1.2, bias=-0.1)\n",
    "X_train2, y_train2, X_test2, y_test2 = train_test_split_tensors(X_all, y_all, split_ratio=0.8)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "final_model = LinearRegressionModelV1()\n",
    "\n",
    "history = train_linear_model(final_model, X_train2, y_train2, X_test2, y_test2, epochs=400, lr=0.01)\n",
    "\n",
    "print('Learned weight:', final_model.weight.item())\n",
    "print('Learned bias  :', final_model.bias.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(history['epoch'], history['train_loss'], label='Train loss')\n",
    "plt.plot(history['epoch'], history['test_loss'], label='Test loss')\n",
    "plt.title('Final Workflow Loss Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('L1 Loss')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1412e462",
   "metadata": {},
   "source": [
    "## Capstone Exercises\n",
    "\n",
    "1. Add Gaussian noise to `y` when creating data and compare final losses.\n",
    "2. Replace SGD with Adam and compare convergence speed.\n",
    "3. Train with very small and very large learning rates and summarize failure modes.\n",
    "4. Add early stopping logic when test loss does not improve for `N` checks.\n",
    "5. Re-run experiments with 3 different random seeds and compare learned parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bc02d9",
   "metadata": {},
   "source": [
    "## Quick Knowledge Check\n",
    "\n",
    "- Why should test data never influence optimizer updates?\n",
    "- What is the difference between `model.train()` and `model.eval()`?\n",
    "- Why is `optimizer.zero_grad()` required every training step?\n",
    "- What does `state_dict()` contain?\n",
    "- When would you prefer MAE over MSE?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
